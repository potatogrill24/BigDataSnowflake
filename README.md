# BigDataSnowflake
Анализ больших данных - лабораторная работа №1 - нормализация данных в снежинку

Одна из задач data engineer при работе с данными BigData трансформировать исходную модель данных источника в аналитическую модель данных. Аналитическая модель данных позволяет исследовать данные и принимать на основе полученных данных решения. Классическими универсальными схемами для анализа данных являются "звезда" и "снежинка". В лабораторной работе вам предстоит потренироваться в трансформации исходных данных из источников в модель данных снежинка.

Что необходимо сделать?

Необходимо данные источника (файлы mock_data.csv с номерами), которые представляют информацию о покупателях, продавцах, поставщиках, магазинах, товарах для домашних питомцев трансформировать в модель снежинка/звезда (факты и измерения с нормализацией).

![Лабораторная работа №1](https://github.com/user-attachments/assets/5bdd26dc-b9e5-4ddc-8df4-456d25503af4)

Алгоритм:
1. Клонируете к себе этот репозиторий.
2. Устанавливаете себе инструмент для работы с запросами SQL (рекомендую DBeaver).
3. Запускаете базу данных PostgreSQL (рекомендую установку через docker).
4. Скачиваете файлы с исходными данными mock_data( * ).csv, где ( * ) номера файлов. Всего 10 файлов, каждый по 1000 строк.
5. Импортируете данные в БД PostgreSQL (например, через механизм импорта csv в DBeaver). Всего в таблице mock_data должно находиться 10000 строк из 10 файлов.
6. Анализируете исходные данные с помощью запросов.
7. Выявляете сущности фактов и измерений.
8. Реализуете скрипты DDL для создания таблиц фактов и измерений.
9. Реализуете скрипты DML для заполнения таблиц фактов и измерений из исходных данных.
10. Проверяете полученный результат.
11. Отправляете результат на проверку лаборантам.
12. Обсуждаете работу с лаборантами.

Что должно быть результатом работы?
1. Репозиторий, в котором есть исходные данные mock_data( * ).csv, где ( * ) номера файлов. Всего 10 файлов, каждый по 1000 строк.
2. Файл docker-compose.yml с установкой PostgreSQL и заполненными данными из файлов mock_data(*).csv.
3. Скрипты DDL (SQL) создания таблиц фактов и измерений в соответствии с моделью снежинка/звезда.
4. Скрипты DML (SQL) заполнения таблиц фактов и измерений из исходных данных.


### Для создания контейнера с БД PostgreSQL воспользуемся следующими командами

1. Создаем контейнер docker, в котором инициализируется БД PostgreSQL, создается таблица mock_data и заполняется из директории ./data
```bash
docker-compose down -v && docker-compose up -d
```

2. Выполним некие запросы в таблицу mock_data, чтобы убедиться в наличии в ней данных и их проанализировать
```bash
docker exec -i bigdatasnowflake-postgres-1 psql -U admin -d mydb < q.sql
```

3. Выполним скрипты ddl.sql и dml.sql для создания и заполнения таблиц фактов и измерений из исходных данных в соответствие с моделью звезда
```bash
docker exec -i bigdatasnowflake-postgres-1 psql -U admin -d mydb < ~/progs/BigDataSnowflake/ddl.sql #создаем
docker exec -i bigdatasnowflake-postgres-1 psql -U admin -d mydb < ~/progs/BigDataSnowflake/dml.sql #заполняем
```

Схема базы данных из DBeaver приложена в файле result_diagram.png
